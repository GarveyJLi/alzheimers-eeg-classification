{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import os\n",
    "import subprocess\n",
    "import mne\n",
    "from pathlib import Path\n",
    "import regex as re\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_cmd = ['bash', os.path.join('EEG_human', 'ds004504-1.0.8.sh')]\n",
    "subprocess.run(download_cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_set(directory):\n",
    "  \"\"\"\n",
    "  Gets a list of all .set files in a directory and its subdirectories.\n",
    "\n",
    "  Args:\n",
    "    directory: The path to the directory.\n",
    "\n",
    "  Returns:\n",
    "    A list of file paths.\n",
    "  \"\"\"\n",
    "  directory = Path(directory)\n",
    "\n",
    "  # Search recursively for .set files\n",
    "  set_files = list(directory.rglob(\"*.set\"))\n",
    "  return set_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = mne.io.read_raw_eeglab((os.path.join('EEG_human', 'ds004504-1.0.8', 'sub-001', 'eeg', 'sub-001_task-eyesclosed_eeg.set')), preload=True)\n",
    "# Convert to Pandas DataFrame\n",
    "df = eeg_data.to_data_frame()\n",
    "df.set_index('time', inplace=True)\n",
    "df.columns = 'sub-001-' + df.columns\n",
    "df = df[df.columns[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_meta = pd.read_table(os.path.join('EEG_human', 'ds004504-1.0.8','participants.tsv'))\n",
    "all_eeg_recordings = get_all_set(os.path.join('EEG_human', 'ds004504-1.0.8', 'derivatives'))\n",
    "all_control_dfs = []\n",
    "all_ad_dfs = []\n",
    "all_ftd_dfs = []\n",
    "for fp in all_eeg_recordings:\n",
    "    try:\n",
    "        temp_eeg_data = mne.io.read_raw_eeglab(fp, preload=True)\n",
    "        temp_df = temp_eeg_data.to_data_frame()\n",
    "        temp_df.set_index('time', inplace=True)\n",
    "        # Get subject ID\n",
    "        subject = re.findall(r'sub-\\d{3}', str(fp))[0]\n",
    "        # Get subject group (C, A, F)\n",
    "        subject_group = sub_meta[sub_meta['participant_id'] == subject].iloc[0]['Group']\n",
    "        # Rename columns to contain subject ID\n",
    "        temp_df.columns = f'{subject}-' + temp_df.columns\n",
    "        # Keep only first three recording channels\n",
    "        temp_df = temp_df[temp_df.columns[:3]]\n",
    "        if subject_group == 'C':\n",
    "            all_control_dfs.append(temp_df)\n",
    "        if subject_group == 'A':\n",
    "            all_ad_dfs.append(temp_df)\n",
    "        elif subject_group == 'F':\n",
    "            all_ftd_dfs.append(temp_df)\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "all_control_subjects = reduce(lambda x, y: pd.merge(x, y, left_index=True, right_index=True, how='outer'), all_control_dfs)\n",
    "all_ad_subjects = reduce(lambda x, y: pd.merge(x, y, left_index=True, right_index=True, how='outer'), all_ad_dfs)\n",
    "all_ftd_subjects = reduce(lambda x, y: pd.merge(x, y, left_index=True, right_index=True, how='outer'), all_ftd_dfs)\n",
    "all_control_subjects.to_csv(os.path.join('EEG_human', 'control_eeg_all.csv'))\n",
    "all_ad_subjects.to_csv(os.path.join('EEG_human', 'ad_eeg_all.csv'))\n",
    "all_ftd_subjects.to_csv(os.path.join('EEG_human', 'ftd_eeg_all.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_EEG_Data = pd.read_csv(os.path.join(\"EEG_human\",\"ad_eeg_all.csv\"))\n",
    "Control_EEG_Data = pd.read_csv(os.path.join(\"EEG_human\",\"control_eeg_all.csv\"))\n",
    "ftd_EEG_Data = pd.read_csv(os.path.join(\"EEG_human\",\"ftd_eeg_all.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing that has already been done:\n",
    "\n",
    "Only the derivatives folder, where the preprocessed data is kept, is covered by this section. The following is the EEG signals’ preprocessing pipeline. \n",
    "\n",
    "* The signals were **re-referenced to the average value of A1-A2** (reference electrodes placed on mastoids) after applying a **Butterworth band-pass filter with a frequency range of 0.5 to 45 Hz**. \n",
    "* The signals were then subjected to the **ASR routine, an automatic artifact reject technique that can eliminate persistent or large-amplitude artifacts, which removed bad data periods that exceeded the maximum acceptable 0.5 s window standard deviation of 17 (which is regarded as a conservative window)**. \n",
    "* **The ICA method (RunICA algorithm) was then used to convert the 19 EEG signals to 19 ICA components [19]**. ICA components categorized as “eye artifacts” or “jaw artifacts” by the EEGLAB platform’s automatic classification method “ICLabel” were automatically excluded. \n",
    "\n",
    "It should be mentioned that, even though the recording was done in a resting state with the eyes closed, eye movement artifacts were still identified in certain EEG recordings. Figure 2 represents a snapshot of the same signal in raw form, and in preprocessed form. It can be observed that severe high frequency artifacts have been removed and baseline correction has been applied.\n",
    "\n",
    "![alt text](images/data_processing.JPG)\n",
    "\n",
    "[Miltiadous, A., Tzimourta, K. D., Afrantou, T., Ioannidis, P., Grigoriadis, N., Tsalikakis, D. G., Angelidis, P., Tsipouras, M. G., Glavas, E., Giannakeas, N., & Tzallas, A. T. (2023). A Dataset of Scalp EEG Recordings of Alzheimer’s Disease, Frontotemporal Dementia and Healthy Subjects from Routine EEG. Data, 8(6), 95. https://doi.org/10.3390/data8060095](https://www.mdpi.com/2306-5729/8/6/95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make nx3 plot\n",
    "def vis_class_channel(df, group):\n",
    "    channels = ['Fp1', 'Fp2', 'F3']\n",
    "    temp_fig, temp_ax = plt.subplots(len(list(filter(lambda x: 'Fp1' in x, df.columns))), len(channels), figsize=(30, 60), sharex=True, sharey=True)\n",
    "    for i in range(len(channels)):\n",
    "        fp_cols = list(filter(lambda x: channels[i] in x, df.columns))\n",
    "        temp_df = df[['time'] + fp_cols].dropna()\n",
    "        for j in range(len(fp_cols)):\n",
    "            sub = fp_cols[j]\n",
    "            temp_ax[j][i].plot(temp_df['time'], temp_df[sub])\n",
    "            temp_ax[j][i].set_xlabel('Time (s)')\n",
    "            temp_ax[j][i].set_ylabel('Signal (µV)')\n",
    "            temp_ax[j][i].set_title(sub)\n",
    "    temp_fig.suptitle(f'{channels[i]} channel for {group} group')    \n",
    "    temp_fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_class_channel(Control_EEG_Data, 'Control')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_class_channel(AD_EEG_Data, 'Alzheimers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Spectrum Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 500\n",
    "T20 = 20\n",
    "T60 = 60\n",
    "T300 = 300\n",
    "\n",
    "AD_EEG_Data_20 = AD_EEG_Data[AD_EEG_Data['time'] <= T20]\n",
    "Control_EEG_Data_20 = Control_EEG_Data[Control_EEG_Data['time'] <= T20]\n",
    "ftd_EEG_Data_20 = ftd_EEG_Data[ftd_EEG_Data['time'] <= T20]\n",
    "\n",
    "AD_EEG_Data_60 = AD_EEG_Data[AD_EEG_Data['time'] <= T60]\n",
    "Control_EEG_Data_60 = Control_EEG_Data[Control_EEG_Data['time'] <= T60]\n",
    "ftd_EEG_Data_60 = ftd_EEG_Data[ftd_EEG_Data['time'] <= T60]\n",
    "\n",
    "AD_EEG_Data_300 = AD_EEG_Data[AD_EEG_Data['time'] <= T300]\n",
    "Control_EEG_Data_300 = Control_EEG_Data[Control_EEG_Data['time'] <= T300]\n",
    "ftd_EEG_Data_300 = ftd_EEG_Data[ftd_EEG_Data['time'] <= T300]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
